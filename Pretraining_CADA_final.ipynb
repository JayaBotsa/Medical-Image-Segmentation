{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLJYULbzyQkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d21dd3-1a08-45ae-957b-a1af14c906c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Project-MONAI/MONAI.git"
      ],
      "metadata": {
        "id": "i_mJHOttyY77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887ab848-9a91-45c9-c64c-a3b25b1dd925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MONAI'...\n",
            "remote: Enumerating objects: 36959, done.\u001b[K\n",
            "remote: Counting objects: 100% (213/213), done.\u001b[K\n",
            "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
            "remote: Total 36959 (delta 104), reused 129 (delta 62), pack-reused 36746\u001b[K\n",
            "Receiving objects: 100% (36959/36959), 64.16 MiB | 39.50 MiB/s, done.\n",
            "Resolving deltas: 100% (29658/29658), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MONAI/\n"
      ],
      "metadata": {
        "id": "nEgBvZg3ybRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b96a0ca-2e99-4040-facb-70f797a8880e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MONAI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e '.[all]'"
      ],
      "metadata": {
        "id": "8j75U2x5ydjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc2e8bf-93d4-4b90-ad38-d2f504fbb3ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/MONAI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = '/content/drive/MyDrive/template/our-git-project/Pretrained_Results_final_12_12_23'"
      ],
      "metadata": {
        "id": "_Kq0f-i4yfiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "from monai.data import ArrayDataset, GridPatchDataset, create_test_image_3d, PatchIter\n",
        "from monai.apps import download_url\n",
        "from monai.utils import set_determinism\n",
        "from monai.losses import DiceCELoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.config import print_config\n",
        "from monai.transforms import (\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    CropForeground,\n",
        "    EnsureChannelFirst,\n",
        "    LoadImage,\n",
        "    Orientation,\n",
        "    RandFlip,\n",
        "    RandCropByPosNegLabel,\n",
        "    RandShiftIntensity,\n",
        "    ScaleIntensityRange,\n",
        "    RandRotate90,\n",
        "    ToTensor,\n",
        ")\n",
        "\n",
        "from monai.metrics import DiceMetric, MeanIoU\n",
        "from monai.networks.nets import UNETR\n",
        "\n",
        "from monai.data import (\n",
        "    DataLoader,\n",
        "    CacheDataset,\n",
        ")\n",
        "\n",
        "print_config()"
      ],
      "metadata": {
        "id": "Mh3s2eBNylKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_determinism(seed=960)"
      ],
      "metadata": {
        "id": "ibe3Y5nCyoyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_pretrained = True\n",
        "\n",
        "\n",
        "if use_pretrained:\n",
        "\n",
        "    dst = '/content/drive/MyDrive/template/our-git-project/Pretrained_Results_final_v4/best_model.pt'\n",
        "\n",
        "    pretrained_path = os.path.normpath(dst)\n"
      ],
      "metadata": {
        "id": "djaXn6RsyrhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from monai.transforms import(\n",
        "    Compose,\n",
        "    EnsureChannelFirstd,\n",
        "    LoadImaged,\n",
        "    Resized,\n",
        "    ToTensord,\n",
        "    Spacingd,\n",
        "    Orientationd,\n",
        "    NormalizeIntensityd,\n",
        "    CropForegroundd,\n",
        "    RandShiftIntensityd,\n",
        "    RandFlipd,\n",
        "    FgBgToIndicesd,\n",
        "    RandRotate90d,\n",
        "    RandCropByPosNegLabeld,\n",
        "    Activations,\n",
        "\n",
        "\n",
        "\n",
        ")\n",
        "from monai.data import DataLoader, Dataset, CacheDataset\n",
        "from monai.utils import set_determinism\n",
        "\n",
        "# Training Hyper-params\n",
        "lr = 1e-4\n",
        "max_iterations = 10000\n",
        "eval_num = 100\n",
        "\n",
        "original_data_folder = '/content/drive/MyDrive/template/our-git-project/preprocessed_images/'\n",
        "mask_data_folder = '/content/drive/MyDrive/template/our-git-project/preprocessed_images/'\n",
        "\n",
        "# List of image file paths\n",
        "images  = sorted(glob(os.path.join(original_data_folder, '*_orig.nii.gz')))\n",
        "segs  = sorted(glob(os.path.join(mask_data_folder, '*_masks.nii.gz')))\n",
        "\n",
        " # define transforms for image and segmentation\n",
        "train_imtrans = Compose(\n",
        "        [\n",
        "            LoadImage(),\n",
        "            EnsureChannelFirst(),\n",
        "            Orientation(axcodes=\"RAS\"),\n",
        "            RandFlip(spatial_axis=[0], prob=0.3,),\n",
        "            RandFlip(spatial_axis=[1],prob=0.3,),\n",
        "            RandFlip(spatial_axis=[2],prob=0.3,),\n",
        "            RandRotate90(prob=0.5, max_k=3, spatial_axes=(0, 2)),\n",
        "            ToTensor(),\n",
        "        ]\n",
        "    )\n",
        "train_segtrans = Compose(\n",
        "        [\n",
        "            LoadImage(),\n",
        "            EnsureChannelFirst(),\n",
        "            Orientation(axcodes=\"RAS\"),\n",
        "            RandFlip(spatial_axis=[0], prob=0.3,),\n",
        "            RandFlip(spatial_axis=[1],prob=0.3,),\n",
        "            RandFlip(spatial_axis=[2],prob=0.3,),\n",
        "            RandRotate90(prob=0.5, max_k=3, spatial_axes=(0, 2)),\n",
        "            ToTensor(),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "val_imtrans = Compose([LoadImage(),\n",
        "            EnsureChannelFirst(),\n",
        "            Orientation(axcodes=\"RAS\"),\n",
        "            ToTensor(),])\n",
        "val_segtrans = Compose([LoadImage(),\n",
        "            EnsureChannelFirst(),\n",
        "            Orientation(axcodes=\"RAS\"),\n",
        "            ToTensor(),])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YuI4MWNAz9sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.utils import first\n",
        "# Define nifti dataset, dataloader\n",
        "train_ds = ArrayDataset(images[:-17], train_imtrans, segs[:-17], train_segtrans)\n",
        "train_loader1 = DataLoader(val_ds, batch_size=5, num_workers=8, pin_memory=torch.cuda.is_available())\n",
        "\n",
        "val_ds = ArrayDataset(images[-17:], val_imtrans, segs[-17:], val_segtrans)\n",
        "val_loader1 = DataLoader(val_ds, batch_size=5, num_workers=8, pin_memory=torch.cuda.is_available())\n",
        "\n",
        "patch_iter = PatchIter(patch_size=(128, 128, 128), start_pos=(0, 0, 0))\n",
        "\n",
        "\n",
        "def img_seg_iter(x):\n",
        "    for img, seg in zip(patch_iter(x[0]), patch_iter(x[1])):\n",
        "        print(img[1], seg[1]) #print coordinates\n",
        "        yield ((img[0], seg[0]), )\n",
        "\n",
        "train_ds1 = GridPatchDataset(train_ds, img_seg_iter, with_coordinates=False)\n",
        "val_ds1 = GridPatchDataset(val_ds, img_seg_iter, with_coordinates=False)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_ds1, batch_size=2, num_workers=8, pin_memory=torch.cuda.is_available()\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_ds1, batch_size=2, num_workers=8, pin_memory=torch.cuda.is_available()\n",
        ")\n",
        "im, seg = first(loader)\n",
        "print(\"image shapes:\", im.shape, seg.shape\n"
      ],
      "metadata": {
        "id": "UyHZ05oOz-y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.networks.nets import UNet\n",
        "from monai.networks.layers import Act, Norm\n",
        "from monai.losses import DiceLoss, DiceCELoss\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = UNETR(\n",
        "    in_channels=1,\n",
        "    out_channels=2,\n",
        "    img_size=(48, 48, 48),\n",
        "    feature_size=16,\n",
        "    hidden_size=768,\n",
        "    mlp_dim=3072,\n",
        "    num_heads=12,\n",
        "    pos_embed=\"conv\",\n",
        "    norm_name=\"instance\",\n",
        "    res_block=True,\n",
        "    dropout_rate=0.0,\n",
        ").to(device)\n",
        "\n",
        "# Load ViT backbone weights into UNETR\n",
        "if use_pretrained is True:\n",
        "    print(\"Loading Weights from the Path {}\".format(pretrained_path))\n",
        "    vit_dict = torch.load(pretrained_path)\n",
        "    vit_weights = vit_dict[\"state_dict\"]\n",
        "\n",
        "    # Remove items of vit_weights if they are not in the ViT backbone (this is used in UNETR).\n",
        "    # For example, some variables names like conv3d_transpose.weight, conv3d_transpose.bias,\n",
        "    # conv3d_transpose_1.weight and conv3d_transpose_1.bias are used to match dimensions\n",
        "    # while pretraining with ViTAutoEnc and are not a part of ViT backbone.\n",
        "    model_dict = model.vit.state_dict()\n",
        "\n",
        "    vit_weights = {k: v for k, v in vit_weights.items() if k in model_dict}\n",
        "    model_dict.update(vit_weights)\n",
        "    model.vit.load_state_dict(model_dict)\n",
        "    del model_dict, vit_weights, vit_dict\n",
        "    print(\"Pretrained Weights Succesfully Loaded !\")\n",
        "\n",
        "elif use_pretrained is False:\n",
        "    print(\"No weights were loaded, all weights being used are randomly initialized!\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "\n",
        "post_label = AsDiscrete(to_onehot=2)\n",
        "post_pred = AsDiscrete(argmax=True, to_onehot=2)\n",
        "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
        "IoU_metric = MeanIoU(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
        "global_step = 0\n",
        "dice_val_best = 0.0\n",
        "IoU_val_best = 0.0\n",
        "global_step_best = 0\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "IoU_values = []"
      ],
      "metadata": {
        "id": "K8o6NkmZ0ZEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict\n",
        "\n",
        "from monai.apps import download_url\n",
        "from monai.utils import set_determinism\n",
        "from monai.losses import DiceCELoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.config import print_config\n",
        "from monai.transforms import (\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    CropForegroundd,\n",
        "    EnsureChannelFirstd,\n",
        "    LoadImaged,\n",
        "    Orientationd,\n",
        "    RandFlipd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    RandShiftIntensityd,\n",
        "    ScaleIntensityRanged,\n",
        "    Spacingd,\n",
        "    RandRotate90d,\n",
        "    ToTensord,\n",
        "    Activations,\n",
        ")\n",
        "\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.networks.nets import UNETR\n",
        "\n",
        "from monai.data import (\n",
        "    DataLoader,\n",
        "    CacheDataset,\n",
        "    load_decathlon_datalist,\n",
        "    decollate_batch,\n",
        ")\n",
        "\n",
        "print_config()"
      ],
      "metadata": {
        "id": "R9V7OG5s03Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(epoch_iterator_val):\n",
        "    model.eval()\n",
        "    dice_vals = []\n",
        "    IoU_vals = []\n",
        "    with torch.no_grad():\n",
        "          for _step, batch in enumerate(epoch_iterator_val):\n",
        "                  val_inputs, val_labels = (batch[\"vol\"].cuda(), batch[\"seg\"].cuda())\n",
        "                  val_outputs = sliding_window_inference(val_inputs, (48, 48, 48), 4, model)\n",
        "                  val_labels_list = decollate_batch(val_labels)\n",
        "                  val_labels_convert = [post_label(val_label_tensor) for val_label_tensor in val_labels_list]\n",
        "                  val_outputs_list = decollate_batch(val_outputs)\n",
        "                  val_output_convert = [post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list]\n",
        "                  dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
        "                  dice = dice_metric.aggregate().item()\n",
        "                  dice_vals.append(dice)\n",
        "                  IoU_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
        "                  IoU = IoU_metric.aggregate().item()\n",
        "                  IoU_vals.append(IoU)\n",
        "                  epoch_iterator_val.set_description(\"Validate (%d / %d Steps) (dice=%2.5f)\" % (global_step, 10.0, dice))\n",
        "                  epoch_iterator_val.set_description(\"Validate (%d / %d Steps) (IoU=%2.5f)\" % (global_step, 10.0, IoU))\n",
        "\n",
        "          dice_metric.reset()\n",
        "          IoU_metric.reset()\n",
        "\n",
        "    mean_dice_val = np.mean(dice_vals)\n",
        "    mean_IoU_val = np.mean(IoU_vals)\n",
        "\n",
        "    return mean_dice_val,mean_IoU_val\n",
        "\n",
        "\n",
        "def train(global_step, train_loader, dice_val_best, IoU_val_best, global_step_best):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    epoch_iterator = tqdm(train_loader, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True)\n",
        "    for step, batch in enumerate(epoch_iterator):\n",
        "              step += 1\n",
        "              x, y = (batch[\"vol\"].cuda(), batch[\"seg\"].cuda())\n",
        "              logit_map = model(x)\n",
        "              loss = loss_function(logit_map, y)\n",
        "              loss.backward()\n",
        "              epoch_loss += loss.item()\n",
        "              optimizer.step()\n",
        "              optimizer.zero_grad()\n",
        "              epoch_iterator.set_description(\"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, max_iterations, loss))\n",
        "\n",
        "              if (global_step % eval_num == 0 and global_step != 0) or global_step == max_iterations:\n",
        "                  epoch_iterator_val = tqdm(val_loader, desc=\"Validate (X / X Steps) (IoU=X.X)\", dynamic_ncols=True)\n",
        "                  dice_val, IoU_val = validation(epoch_iterator_val)\n",
        "\n",
        "                  epoch_loss /= step\n",
        "                  epoch_loss_values.append(epoch_loss)\n",
        "                  metric_values.append(dice_val)\n",
        "                  IoU_values.append(IoU_val)\n",
        "                  if dice_val > dice_val_best:\n",
        "                      dice_val_best = dice_val\n",
        "                      global_step_best = global_step\n",
        "                      torch.save(model.state_dict(), os.path.join(model_dir, \"best_metric_model.pth\"))\n",
        "                      print(\n",
        "                          \"Model Was Saved ! Current Best Avg. dice: {} Current Avg. dice: {}\".format(dice_val_best, dice_val)\n",
        "                      )\n",
        "                  else:\n",
        "                      print(\n",
        "                          \"Model Was Not Saved ! Current Best Avg. dice: {} Current Avg. dice: {}\".format(\n",
        "                              dice_val_best, dice_val\n",
        "                          )\n",
        "                      )\n",
        "                  if IoU_val > IoU_val_best:\n",
        "                      IoU_val_best = IoU_val\n",
        "                      print(\n",
        "                          \"Model Was Saved ! Current Best Avg. IoU: {} Current Avg. IoU: {}\".format(IoU_val_best, IoU_val)\n",
        "                      )\n",
        "                  else:\n",
        "                      print(\n",
        "                          \"Model Was Not Saved ! Current Best Avg. IoU: {} Current Avg. IoU: {}\".format(\n",
        "                              IoU_val_best, IoU_val\n",
        "                          )\n",
        "                      )\n",
        "\n",
        "\n",
        "                  plt.figure(1, (12, 6))\n",
        "                  plt.subplot(1, 2, 1)\n",
        "                  plt.title(\"Iteration Average Loss\")\n",
        "                  x = [eval_num * (i + 1) for i in range(len(epoch_loss_values))]\n",
        "                  y = epoch_loss_values\n",
        "                  plt.xlabel(\"Iteration\")\n",
        "                  plt.plot(x, y)\n",
        "                  plt.grid()\n",
        "                  plt.subplot(1, 2, 2)\n",
        "                  plt.title(\"Val Mean Dice\")\n",
        "                  x = [eval_num * (i + 1) for i in range(len(metric_values))]\n",
        "                  y = metric_values\n",
        "                  plt.xlabel(\"Iteration\")\n",
        "                  plt.plot(x, y)\n",
        "                  plt.grid()\n",
        "                  plt.savefig(os.path.join(model_dir, \"unet_finetune_quick_update.png\"))\n",
        "                  plt.clf()\n",
        "                  plt.close(1)\n",
        "\n",
        "              global_step += 1\n",
        "    return global_step, dice_val_best, IoU_val_best, global_step_best\n",
        "\n",
        "\n",
        "while global_step < max_iterations:\n",
        "    global_step, dice_val_best, IoU_val_best, global_step_best = train(global_step, train_loader, dice_val_best, IoU_val_best, global_step_best)\n",
        "model.load_state_dict(torch.load(os.path.join(model_dir, \"best_metric_model.pth\")))\n",
        "\n",
        "print(f\"train completed, best_metric: {dice_val_best:.4f} \" f\"at iteration: {global_step_best}\")"
      ],
      "metadata": {
        "id": "14rC3BXV1Ny0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1, (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Iteration Average Loss\")\n",
        "x = [eval_num * (i + 1) for i in range(len(epoch_loss_values))]\n",
        "y = epoch_loss_values\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.plot(x, y)\n",
        "plt.grid()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Val Mean Dice\")\n",
        "x = [eval_num * (i + 1) for i in range(len(metric_values))]\n",
        "y = metric_values\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.plot(x, y)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rSJLVZH71Xr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "original_data_folder = '/content/drive/MyDrive/template/our-git-project/preprocessed_images/'\n",
        "mask_data_folder = '/content/drive/MyDrive/template/our-git-project/preprocessed_images/'\n",
        "\n",
        "# List of image file paths\n",
        "vol  = sorted(glob(os.path.join(original_data_folder, '*_orig.nii.gz')))\n",
        "segs  = sorted(glob(os.path.join(mask_data_folder, '*_masks.nii.gz')))\n",
        "\n",
        "\n",
        "data_dicts = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(vol, segs)]\n",
        "train_files, test_files = data_dicts[:-25], data_dicts[-25:]\n",
        "\n",
        "\n",
        "test_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"vol\", \"seg\"]),\n",
        "            EnsureChannelFirstd(keys=[\"vol\", \"seg\"]),\n",
        "            #Spacingd(keys=[\"vol\", \"seg\"], pixdim=pixdim, mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
        "            #NormalizeIntensityd(keys=\"vol\", nonzero=True, channel_wise=True),\n",
        "            CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
        "            RandCropByPosNegLabeld(\n",
        "            keys=[\"vol\", \"seg\"],\n",
        "            label_key=\"seg\",\n",
        "            spatial_size=(128, 128, 128),\n",
        "            pos=4,\n",
        "            neg=1,\n",
        "            num_samples=10,\n",
        "            image_key=\"vol\",\n",
        "            image_threshold=0,\n",
        "            ),\n",
        "            ToTensord(keys=[\"vol\", \"seg\"]),\n",
        "\n",
        "\n",
        "        ]\n",
        "    )\n",
        "\n",
        "test_ds = CacheDataset(data=test_files, transform=test_transforms, cache_rate=1.0)\n",
        "test_loader = DataLoader(test_ds, batch_size=1)"
      ],
      "metadata": {
        "id": "OJYH5RYw1bxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = UNETR(\n",
        "    in_channels=1,\n",
        "    out_channels=2,\n",
        "    img_size=(48, 48, 48),\n",
        "    feature_size=16,\n",
        "    hidden_size=768,\n",
        "    mlp_dim=3072,\n",
        "    num_heads=12,\n",
        "    pos_embed=\"conv\",\n",
        "    norm_name=\"instance\",\n",
        "    res_block=True,\n",
        "    dropout_rate=0.0,\n",
        ").to(device)\n"
      ],
      "metadata": {
        "id": "I1JdoFGp1ctx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\n",
        "    os.path.join(model_dir, \"best_metric_model.pth\")))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "Zw_o9XGc1l7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.utils import first\n",
        "sw_batch_size = 10\n",
        "roi_size = (48, 48, 48)\n",
        "with torch.no_grad():\n",
        "    test_patient = first(test_loader)\n",
        "    t_volume = test_patient['vol'].cuda()\n",
        "    val_labels = test_patient['seg'].cuda()\n",
        "\n",
        "    val_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n",
        "    val_labels_list = decollate_batch(val_labels)\n",
        "    val_labels_convert = [post_label(val_label_tensor) for val_label_tensor in val_labels_list]\n",
        "    val_outputs_list = decollate_batch(val_outputs)\n",
        "    val_output_convert = [post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list]\n",
        "    dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
        "    dice = dice_metric.aggregate().item()\n",
        "    IoU_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
        "    IoU = IoU_metric.aggregate().item()\n",
        "    print(\"Test Dice Value: \",dice)\n",
        "    print(\"Test IoU Value: \",IoU)"
      ],
      "metadata": {
        "id": "37XT9Pfepjx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\n",
        "    os.path.join(model_dir, \"best_metric_model.pth\")))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "        test_patient = first(test_loader)\n",
        "        t_volume = test_patient['vol']\n",
        "        #t_segmentation = test_patient['seg']\n",
        "\n",
        "        test_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n",
        "        sigmoid_activation = Activations(sigmoid=True)\n",
        "        test_outputs = sigmoid_activation(test_outputs)\n",
        "        test_outputs = test_outputs > 0.5\n",
        "\n",
        "        for i in range(45):\n",
        "            # plot the slice [:, :, 80]\n",
        "            plt.figure(\"check\", (20, 4))\n",
        "            plt.subplot(1, 7, 1)\n",
        "            plt.title(f\"image {i}\")\n",
        "            plt.imshow(test_patient['vol'].detach().cpu()[0, 0, :, :, i], cmap=\"gray\")\n",
        "            plt.subplot(1, 7, 2)\n",
        "            plt.title(f\"argmax {i}\")\n",
        "            argmax = [AsDiscrete(argmax=True)(j) for j in decollate_batch(test_outputs)]\n",
        "            plt.imshow(argmax[0].detach().cpu()[0, :, :, i])\n",
        "            plt.subplot(1, 7, 3)\n",
        "            plt.title(f\"largest {i}\")\n",
        "            largest = [KeepLargestConnectedComponent(applied_labels=[1])(j) for j in argmax]\n",
        "            plt.imshow(largest[0].detach().cpu()[0, :, :, i])\n",
        "            plt.subplot(1, 7, 4)\n",
        "            plt.title(f\"contour {i}\")\n",
        "            contour = [LabelToContour()(j) for j in largest]\n",
        "            plt.imshow(contour[0].detach().cpu()[0, :, :, i])\n",
        "            plt.subplot(1, 7, 5)\n",
        "            plt.title(f\"map image {i}\")\n",
        "            map_image = contour[0] + t_volume.to(device)[0]\n",
        "            plt.imshow(map_image.detach().cpu()[0, :, :, i], cmap=\"gray\")\n",
        "            plt.subplot(1, 7, 6)\n",
        "            plt.title(f\"output {i}\")\n",
        "            plt.imshow(test_outputs_1.detach().cpu()[0, 1, :, :, i])\n",
        "            plt.subplot(1, 7, 7)\n",
        "            plt.title(f\"label {i}\")\n",
        "            plt.imshow(test_patient[\"seg\"][0, 0, :, :, i] != 0)\n",
        "            plt.show()"
      ],
      "metadata": {
        "id": "DFeMoKN-UqIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\n",
        "    os.path.join(model_dir, \"best_metric_model.pth\")))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, val_data in enumerate(test_loader):\n",
        "      for j in range(48):\n",
        "        roi_size = (48, 48, 48)\n",
        "        sw_batch_size = 10\n",
        "        val_data = val_data[\"vol\"].to(device)\n",
        "        val_output = sliding_window_inference(val_data, roi_size, sw_batch_size, model)\n",
        "        plt.figure(\"check\", (20, 4))\n",
        "        plt.subplot(1, 5, 1)\n",
        "        plt.title(f\"image {i}\")\n",
        "        plt.imshow(val_data.detach().cpu()[0, 0, :, :, j], cmap=\"gray\")\n",
        "        plt.subplot(1, 5, 2)\n",
        "        plt.title(f\"argmax {i}\")\n",
        "\n",
        "        argmax = [AsDiscrete(argmax=True)(i) for i in decollate_batch(val_output)]\n",
        "        plt.imshow(argmax[0].detach().cpu()[0, :, :, j])\n",
        "        plt.subplot(1, 5, 3)\n",
        "        plt.title(f\"largest {i}\")\n",
        "        largest = [KeepLargestConnectedComponent(applied_labels=[1])(i) for i in argmax]\n",
        "        plt.imshow(largest[0].detach().cpu()[0, :, :, j])\n",
        "        plt.subplot(1, 5, 4)\n",
        "        plt.title(f\"contour {i}\")\n",
        "        contour = [LabelToContour()(i) for i in largest]\n",
        "        plt.imshow(contour[0].detach().cpu()[0, :, :, j])\n",
        "        plt.subplot(1, 5, 5)\n",
        "        plt.title(f\"map image {i}\")\n",
        "        map_image = contour[0] + val_data[0]\n",
        "        plt.imshow(map_image.detach().cpu()[0, :, :, j], cmap=\"gray\")\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "NZGbyCvcUJNU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}